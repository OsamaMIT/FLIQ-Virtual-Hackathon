{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef808767",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qiskit torch numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.primitives import StatevectorEstimator\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "#Prep Training Data (Breast Cancer Wisconsin)\n",
    "\n",
    "#Load the data file\n",
    "df = pd.read_csv(\"data\\\\wdbc.data\", header=None)\n",
    "\n",
    "#Assign column names\n",
    "columns = ['id', 'diagnosis'] + [f'feature_{i}' for i in range(1, 31)]\n",
    "df.columns = columns\n",
    "\n",
    "#Drop the ID column\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "#Encode diagnosis: M = 1, B = 0\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "#Convert to numpy arrays\n",
    "X = df.drop(columns=['diagnosis']).values.astype(np.float32)\n",
    "Y = df['diagnosis'].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "#Normalize features manually (z-score)\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X = (X - mean) / std\n",
    "\n",
    "#Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "#Manual train/test split (80/20)\n",
    "num_samples = X_tensor.shape[0]\n",
    "indices = torch.randperm(num_samples)\n",
    "\n",
    "split_idx = int(num_samples * 0.8)\n",
    "train_indices = indices[:split_idx]\n",
    "test_indices = indices[split_idx:]\n",
    "\n",
    "X_train = X_tensor[train_indices]\n",
    "Y_train = Y_tensor[train_indices]\n",
    "X_test = X_tensor[test_indices]\n",
    "Y_test = Y_tensor[test_indices]\n",
    "\n",
    "#VQA Circuit\n",
    "n_qubits = 2\n",
    "params = ParameterVector('theta', length=4)\n",
    "\n",
    "def create_vqa_circuit(input_data, weights):\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    print(\"Make changes here\")\n",
    "    return qc\n",
    "\n",
    "#Qiskit StatevectorEstimator primitive\n",
    "estimator = StatevectorEstimator()\n",
    "observables = [SparsePauliOp(\"ZI\")]\n",
    "\n",
    "#PyTorch Custom Autograd Function For VQA Layer\n",
    "class VQALayerFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input_tensor, weights):\n",
    "        input_vals = input_tensor.detach().numpy()\n",
    "        weight_vals = weights.detach().numpy()\n",
    "        ctx.save_for_backward(input_tensor, weights)\n",
    "\n",
    "        qc = create_vqa_circuit(input_vals, weight_vals)\n",
    "        job = estimator.run([(qc, observables)])\n",
    "        expval = job.result()[0].data.evs\n",
    "\n",
    "        return torch.tensor([expval], dtype=torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input_tensor, weights = ctx.saved_tensors\n",
    "        input_vals = input_tensor.detach().numpy()\n",
    "        weight_vals = weights.detach().numpy()\n",
    "        shift = np.pi / 2\n",
    "        grads = []\n",
    "\n",
    "        for i in range(len(weight_vals)):\n",
    "            print(\"Make changes here\")\n",
    "\n",
    "        grads_tensor = torch.tensor(grads, dtype=torch.float32)\n",
    "        return None, (grad_output.view(-1)[0] * grads_tensor).view(-1)\n",
    "\n",
    "#Quantum Layer as PyTorch Module\n",
    "class VQALayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(4)) #4 trainable parameters for the circuit\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.stack([VQALayerFunction.apply(x[i], self.weights) for i in range(x.size(0))]).view(-1, 1)\n",
    "\n",
    "#Full Hybrid Model\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classical = nn.Linear(X_tensor.shape[1], 2) #Classic preprocessing layer\n",
    "        self.quantum = VQALayer() #VQA layer\n",
    "        self.output = nn.Linear(1, 1) #Final classical layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classical(x)\n",
    "        x = torch.tanh(x)  #Activation before quantum layer\n",
    "        x = self.quantum(x)\n",
    "        x = self.output(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "model = HybridModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "#Training Loop\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(X_train)\n",
    "    loss = loss_fn(preds, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        acc = ((preds > 0.5).float() == Y_train).float().mean()\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f} | Accuracy: {acc.item()*100:.2f}%\")\n",
    "\n",
    "#Implement Testing Loop:\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ef808767",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef808767",
        "outputId": "d061332d-cc03-4e6d-cba4-5434e315cdbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.16.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.13.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit torch numpy pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5808d442",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "5808d442",
        "outputId": "cdc9565a-2c31-4eef-bd87-ed4e4d5f97e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Avg Loss: 0.6268 | Accuracy: 83.74%\n",
            "Epoch 2 | Avg Loss: 0.3541 | Accuracy: 92.53%\n",
            "Epoch 3 | Avg Loss: 0.2396 | Accuracy: 93.63%\n",
            "Epoch 4 | Avg Loss: 0.1946 | Accuracy: 94.29%\n",
            "Epoch 5 | Avg Loss: 0.1946 | Accuracy: 94.95%\n",
            "Epoch 6 | Avg Loss: 0.1704 | Accuracy: 94.73%\n",
            "Epoch 7 | Avg Loss: 0.1661 | Accuracy: 95.60%\n",
            "Epoch 8 | Avg Loss: 0.1562 | Accuracy: 94.95%\n",
            "Best weights: tensor([ 1.6283, -0.0642, -0.0969,  0.4047, -0.7979,  0.8536,  0.3498,  3.4695,\n",
            "         0.1063, -0.4137, -1.7513,  0.7449,  1.2030, -0.9913, -1.3877, -0.3289,\n",
            "         1.4306, -0.2583, -0.7917, -0.0676])\n",
            " Best ROCAUC: 0.986305081919373\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cannot assign 'torch.FloatTensor' as parameter 'weights' (torch.nn.Parameter or None expected)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9321302b4dd9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;31m# Load best params at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;31m#Implement Testing Loop:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m   1957\u001b[0m                     \u001b[0;34mf\"cannot assign '{torch.typename(value)}' as parameter '{name}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m                     \u001b[0;34m\"(torch.nn.Parameter or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot assign 'torch.FloatTensor' as parameter 'weights' (torch.nn.Parameter or None expected)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from qiskit import QuantumCircuit\n",
        "#ParameterVector was redudant\n",
        "from qiskit.primitives import StatevectorEstimator\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "#To control the random trainable parameters during development:\n",
        "torch.manual_seed(42)\n",
        "\n",
        "#Prep Training Data (Breast Cancer Wisconsin)\n",
        "\n",
        "#Load the data file\n",
        "df = pd.read_csv(\"wdbc.data\", header=None)\n",
        "\n",
        "#Assign column names\n",
        "columns = ['id', 'diagnosis'] + [f'feature_{i}' for i in range(1, 31)]\n",
        "df.columns = columns\n",
        "\n",
        "#Drop the ID column\n",
        "df = df.drop(columns=['id'])\n",
        "\n",
        "#Encode diagnosis: M = 1, B = 0\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "#Convert to numpy arrays\n",
        "X = df.drop(columns=['diagnosis']).values.astype(np.float32)\n",
        "Y = df['diagnosis'].values.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "#Normalize features manually (z-score)\n",
        "mean = X.mean(axis=0)\n",
        "std = X.std(axis=0)\n",
        "X = (X - mean) / std\n",
        "\n",
        "#Convert to torch tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "#Manual train/test split (80/20)\n",
        "num_samples = X_tensor.shape[0]\n",
        "indices = torch.randperm(num_samples)\n",
        "\n",
        "split_idx = int(num_samples * 0.8)\n",
        "train_indices = indices[:split_idx]\n",
        "test_indices = indices[split_idx:]\n",
        "\n",
        "X_train = X_tensor[train_indices]\n",
        "Y_train = Y_tensor[train_indices]\n",
        "X_test = X_tensor[test_indices]\n",
        "Y_test = Y_tensor[test_indices]\n",
        "\n",
        "#VQA Circuit\n",
        "n_qubits = 4\n",
        "#Params were redudant\n",
        "\n",
        "def create_vqa_circuit(input_data, weights):\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    shift = 0  # index into weights array\n",
        "\n",
        "    # 1) Triple data re‑uploading with CZ entanglement\n",
        "    for _ in range(3):\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(input_data[i % len(input_data)], i)\n",
        "        for i in range(n_qubits - 1):\n",
        "            qc.cz(i, i + 1)\n",
        "        qc.barrier()\n",
        "\n",
        "    # 2) Two variational layers: mixed-axis rotations + ring CNOTs\n",
        "    for _ in range(2):\n",
        "        # each layer has 2 rotations per qubit\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(weights[shift], i); shift += 1\n",
        "            qc.ry(weights[shift], i); shift += 1\n",
        "        # ring entanglement\n",
        "        for i in range(n_qubits):\n",
        "            qc.cx(i, (i + 1) % n_qubits)\n",
        "        qc.barrier()\n",
        "\n",
        "    # 3) Final fine‑tune layer: one Ry per qubit\n",
        "    for i in range(n_qubits):\n",
        "        qc.ry(weights[shift], i)\n",
        "        shift += 1\n",
        "\n",
        "    return qc\n",
        "\n",
        "\n",
        "#Qiskit StatevectorEstimator primitive\n",
        "estimator = StatevectorEstimator()\n",
        "#observables = [ SparsePauliOp(\"Z\" + \"I\" * (n_qubits-1)) ] #Single multi-qubit gate\n",
        "observables = [\n",
        "    SparsePauliOp(\"\".join(\"Z\" if j == i else \"I\" for j in range(n_qubits)))\n",
        "    for i in range(n_qubits)\n",
        "] #A weighted sum will be applied using trainable reeadout parameters\n",
        "\n",
        "#PyTorch Custom Autograd Function For VQA Layer\n",
        "class VQALayerFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input_tensor, weights):\n",
        "        input_vals = input_tensor.detach().numpy()\n",
        "        weight_vals = weights.detach().numpy()\n",
        "        ctx.save_for_backward(input_tensor, weights)\n",
        "\n",
        "        qc = create_vqa_circuit(input_vals, weight_vals)\n",
        "        job = estimator.run([(qc, observables)])\n",
        "        expval = job.result()[0].data.evs\n",
        "\n",
        "        return torch.tensor([expval], dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input_tensor, weights = ctx.saved_tensors\n",
        "        input_vals = input_tensor.detach().numpy()\n",
        "        weight_vals = weights.detach().numpy()\n",
        "        shift = np.pi / 2\n",
        "        grads = []\n",
        "\n",
        "        for i in range(len(weight_vals)): # Grad is calculated using parameter shift rule\n",
        "            #print(\"Make changes here\")\n",
        "            #w abbreviates weight_vals\n",
        "            w_plus, w_minus = weight_vals.copy(), weight_vals.copy()\n",
        "            w_plus[i]  += shift\n",
        "            w_minus[i] -= shift\n",
        "\n",
        "            circuit_plus  = create_vqa_circuit(input_vals, w_plus)\n",
        "            circuit_minus = create_vqa_circuit(input_vals, w_minus)\n",
        "\n",
        "            EV_plus  = estimator.run([(circuit_plus, observables)]).result()[0].data.evs[0]\n",
        "            EV_minus = estimator.run([(circuit_minus, observables)]).result()[0].data.evs[0]\n",
        "\n",
        "            grads.append( 0.5 * (EV_plus - EV_minus) )\n",
        "\n",
        "\n",
        "        grads_tensor = torch.tensor(grads, dtype=torch.float32)\n",
        "        return None, (grad_output.view(-1)[0] * grads_tensor).view(-1)\n",
        "\n",
        "#Quantum Layer as PyTorch Module\n",
        "class VQALayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(5 * n_qubits)) #trainable parameters for the circuit\n",
        "        self.best_weights = self.weights.detach().clone() #to capture the best weights during training\n",
        "        self.readout_w = nn.Parameter(torch.ones(n_qubits) / n_qubits) #trainable parameters for the a weighted Pauli sum observable\n",
        "\n",
        "    def forward(self, x):\n",
        "        #run quantum circuit on each sample\n",
        "        expvals = torch.stack([\n",
        "            VQALayerFunction.apply(x[i], self.weights)\n",
        "            for i in range(x.size(0))\n",
        "        ], dim=0).squeeze(1)  #tensor shape [batch, n_qubits]\n",
        "\n",
        "        return expvals #Returns expectation for each qubit\n",
        "\n",
        "        #return torch.stack([VQALayerFunction.apply(x[i], self.weights) for i in range(x.size(0))]).view(-1, 1)\n",
        "\n",
        "#Full Hybrid Model\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.classical = nn.Linear(X_tensor.shape[1], n_qubits) #Classic preprocessing layer\n",
        "        self.quantum = VQALayer() #VQA layer\n",
        "        self.readout_w = nn.Parameter(torch.ones(n_qubits))\n",
        "        #self.output = nn.Linear(n_qubits, 1) #Final classical layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.classical(x)\n",
        "        x = torch.tanh(x)  #Activation before quantum layer\n",
        "        x = self.quantum(x)\n",
        "\n",
        "        x = (x * self.readout_w).sum(dim=1, keepdim=True)\n",
        "        #x = self.output(x)\n",
        "\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "model = HybridModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.04)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "#Training Loop\n",
        "batch_size = 16\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "best_rocauc = 0\n",
        "\n",
        "for epoch in range(8):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    #Iterate over batches\n",
        "    for Xb, Yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(Xb)\n",
        "        loss = loss_fn(preds, Yb)\n",
        "        loss.backward()\n",
        "\n",
        "        #Print gradient norms for all parameters\n",
        "        # for name, param in model.named_parameters():\n",
        "        #     if param.grad is not None:\n",
        "        #         print(f\"{name} grad_norm = {param.grad.norm():.4f}\")\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    #After all batches, compute epoch‑level metrics on the full training set\n",
        "    with torch.no_grad():\n",
        "        preds_full = model(X_train)\n",
        "        acc_full   = ((preds_full > 0.5).float() == Y_train).float().mean()\n",
        "        y_scores   = preds_full.view(-1).cpu().numpy()\n",
        "        y_true     = Y_train.view(-1).cpu().numpy().astype(int)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f} | Accuracy: {acc_full.item()*100:.2f}%\")\n",
        "\n",
        "    #Record best params\n",
        "    rocauc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    if rocauc > best_rocauc:\n",
        "        model.quantum.best_weights = model.quantum.weights.detach().clone()\n",
        "        best_rocauc = rocauc\n",
        "\n",
        "    if epoch == 7:\n",
        "        print(f\"Best weights: {model.quantum.best_weights}\\n Best ROCAUC: {best_rocauc}\")\n",
        "\n",
        "#Implement Testing Loop:\n",
        "#print(\"Make changes here\")\n",
        "\n",
        "#TO SOLVE THE ERROR IN TESTING WITHOUT RETRAINING, THE TESTING CODE WAS SEPERATED TO PERSERVE THIS CELL'S OUTPUTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4vs_RtVYPyz4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vs_RtVYPyz4",
        "outputId": "0bcea94b-d24d-418b-ae16-0e732c512dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.8860\n",
            "Precision:      0.8511\n",
            "Recall:         0.8696\n",
            "F1-Score:       0.8602\n",
            "ROC AUC:        0.9680\n",
            "Confusion Matrix:\n",
            "[[61  7]\n",
            " [ 6 40]]\n"
          ]
        }
      ],
      "source": [
        "#Implement Testing Loop:\n",
        "#print(\"Make changes here\")\n",
        "#Load best params at the end\n",
        "model.quantum.weights.data.copy_(model.quantum.best_weights.detach().clone())\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    #Forward pass on test set\n",
        "    preds_test = model(X_test).view(-1).cpu().numpy()\n",
        "    y_true = Y_test.view(-1).cpu().numpy().astype(int)\n",
        "    y_pred_labels = (preds_test > 0.5).astype(int)\n",
        "\n",
        "    #Compute metrics\n",
        "    acc    = accuracy_score(y_true, y_pred_labels)\n",
        "    prec   = precision_score(y_true, y_pred_labels)\n",
        "    rec    = recall_score(y_true, y_pred_labels)\n",
        "    f1     = f1_score(y_true, y_pred_labels)\n",
        "    rocauc = roc_auc_score(y_true, preds_test)\n",
        "    cm     = confusion_matrix(y_true, y_pred_labels)\n",
        "\n",
        "#Print results\n",
        "print(f\"Test Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision:      {prec:.4f}\")\n",
        "print(f\"Recall:         {rec:.4f}\")\n",
        "print(f\"F1-Score:       {f1:.4f}\")\n",
        "print(f\"ROC AUC:        {rocauc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "lV9aqz34Ct8i",
      "metadata": {
        "id": "lV9aqz34Ct8i"
      },
      "outputs": [],
      "source": [
        "#Save just the best weights tensor\n",
        "torch.save(model.quantum.best_weights, \"quantum_best_weights.pt\")\n",
        "\n",
        "#To load it back:\n",
        "#loaded_weights = torch.load(\"quantum_best_weights.pt\")\n",
        "#and assign it via:\n",
        "#model.quantum.weights.data.copy_(loaded_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "yR1hIdZTPcLR",
      "metadata": {
        "id": "yR1hIdZTPcLR"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"best_quantum_weights\": model.quantum.best_weights\n",
        "}, \"full_model_checkpoint.pt\")\n",
        "\n",
        "#Load with:\n",
        "#checkpoint = torch.load(\"full_model_checkpoint.pt\")\n",
        "#model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "#model.quantum.weights.data.copy_(checkpoint[\"best_quantum_weights\"])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
